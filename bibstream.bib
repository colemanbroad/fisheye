https://www.miccai2018.org/files/downloads/MICCAI2018-Accepted-Papers-IDs-and-Titles.pdf

PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation
http://openaccess.thecvf.com/content_cvpr_2017/papers/Qi_PointNet_Deep_Learning_CVPR_2017_paper.pdf
Deep Learning with Point Cloud input

Learning to Segment 3D Linear Structures Using Only 2D Annotations
MICCAI 2018
TAGS: toread
Talks about 2D annotations?

Unsupervised Learning for Fast Probabilistic Diffeomorphic Registration
MICCAI 2018

Conditional Entropy as a Supervised Primitive Segmentation Loss Function
MICCAI 2018

Spatial Transformer Networks
http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf
Module you can insert into a network that allows you to learn simple spatial transformations via backprop. In practice the network will learn to do affine registration of MNIST digits into canonical orientation/scale early in the network before space has been turned completely into features.

An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution
https://www.reddit.com/r/MachineLearning/comments/90n40l/dautopsy_of_a_deep_learning_paper_quite_brutal/
Add coordinates as channels will help for some problems

CFCM: segmentation via Coarse to Fine Context Memory
MICCAI 2018
https://arxiv.org/pdf/1806.01413.pdf
Using LSTM for improving on the concatenation and summation skip connections of the Unet and res net. for better "feature forwarding" for combining features from multiple scales. 
improvement in DICE score is in 3rd decimal digit on datasets with high ambiguity in ground truth and around 50 sample images.
models are also quite large: ResNet and CFCM 18,34,50,101.

On the Effect of Inter-observer Variability for a Reliable Estimation of Uncertainty of Medical Image Segmentation
https://arxiv.org/pdf/1806.02562.pdf
> The  results  highlight  the  negative  effect of fusion methods applied in deep learning, to obtain reliable estimates of segmentation uncertainty. Additionally, we show that the learned ob- servers’ uncertainty can be combined with current standard Monte Carlo dropout Bayesian neural networks to characterize uncertainty of model’s parameters.

Cell Detection in Microscopy Images with Deep Convolutional Neural Network and Compressed Sensing 
https://arxiv.org/pdf/1708.03307.pdf
Use CNN for cell detection with very strange output encoding.
Instead of having an n-hot encoding of cell centerpoints ontop of the original image. They do "random projections" to project cells on 1D line. The network then does L1 minimization (compressed sensing) reconstruction of the 2D centroids.

Deep Learning Based Instance Segmentation in 3D Biomedical Images Using Weak Annotation
MICCAI 2018
They test on the ISBI C. Elegans dataset! Require 3D bounding box annotation and full 3D segmentation from subset. Don't use 2D seg measure or do tracking.

More Knowledge is Better: Cross - Modality Volume Completion and 3D+2D Segmentation for Intracardiac Echocardiography Contouring
MICCAI 2018

Deep Learning in Medical Imaging
https://www.youtube.com/watch?v=2_Jv11VpOF4

5 Minute Teaser Presentation of the U-net: Convolutional Networks for Biomedical Image Segmentation
https://www.youtube.com/watch?v=81AvQQnpG4Q

Quantitative mapping and minimization of super-resolution optical imaging artifacts
Sian Culley's Squirrel paper

Fast live-cell conventional fluorophore nanoscopy with ImageJ through super-resolution radial fluctuations
SRRF "surf" paper.
Another paper from the Henriques lab.
Pairs with the Sian Culley paper.

Evolving simple programs for playing Atari games
Evolutionary algorithms play atari games using raw pixel input. meant to compete with DL alternatives. Cartesian Genetic Programming.

@article{xie2018microscopy,
  title={Microscopy cell counting and detection with fully convolutional regression networks},
  author={Xie, Weidi and Noble, J Alison and Zisserman, Andrew},
  journal={Computer methods in biomechanics and biomedical engineering: Imaging \& Visualization},
  volume={6},
  number={3},
  pages={283--292},
  year={2018},
  publisher={Taylor \& Francis}}
cited 70 !!! OK, but it's actually a 2016 paper according to Martin & Uwe.
Weidi Xie, J. Alison Noble & Andrew Zisserman
use convolutional neural networks (CNNs) to regress a cell  spatial  density  map. integrate the density to count cells. great idea for cell detection.
- If this is actually a 2016 paper then why haven't they extended it to 3D yet?

Learning to detect and track cells for quantitative analysis of time-lapse microscopic image sequences
2015. Pedro D. Kostelec ; Leo M. Carlin ; Ben Glocker
12th International Symposium on Biomedical Imaging (ISBI)

Why bioimage informatics matters
Gene Myers
June 2012. Nature Methods.

Noise2Noise: Learning Image Restoration without Clean Data
https://arxiv.org/pdf/1803.04189.pdf
You don't need denoised ground truth to learn to denoise with NNs!
You just need two noisy examples sampled under the same conditions.
2018. Jaakko Lehtinen, Timo Aila. 

@article{litjens2017survey,
  title={A survey on deep learning in medical image analysis},
  author={Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and van der Laak, Jeroen AWM and Van Ginneken, Bram and S{\'a}nchez, Clara I},
  journal={Medical image analysis},
  volume={42},
  pages={60--88},
  year={2017},
  publisher={Elsevier}}
cited 459
Dec 2017

V-net: Fully convolutional neural networks for volumetric medical image segmentation
2016. 327 citations.

The importance of skip connections in biomedical image segmentation
2016. 70. 
- How does this make sense in light of MS-D nets?

http://www.fast.ai/2018/07/02/adam-weight-decay/
AdamW and Super-convergence is now the fastest way to train neural nets
Written: 02 Jul 2018 by Sylvain Gugger and Jeremy Howard

Size-invariant cell nucleus segmentation in 3-D microscopy
Sundaresh Ram ; Jeffrey J. Rodríguez ; Giovanni Bosco
2012 IEEE Southwest Symposium on Image Analysis and Interpretation

## Wed Jul 25 18:41:42 2018

3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation
MICCAI 2016
Özgün ÇiçekEmail authorAhmed AbdulkadirSoeren S. LienkampThomas BroxOlaf Ronneberger
- Milletari et al. [9] present a CNN combined with a Hough voting approach for 3D segmentation. However, their method is not end-to-end and only works for compact blob-like structures.
- We also introduce batch normalization (“BN”) before each ReLU.
- 77 slices labeled. did 3-fold cross validation.
- IoU in [82,86] for same image (no BN)
- IoU in [65,78] for new image (no BN)
- Cites two already existing 3D CNNs for mri brain segmentation
    + cites Hough-CNN
questions:
- what about neuron tracing in EM scanning images?
    + different sort of data. resolution and image quality doesn't change as function of space. mri is more similar to spim in that quality must degrade as you move deeper.

Hough-CNN: deep learning for segmentation of deep brain regions in MRI and ultrasound

Thu Aug  2 12:57:43 2018

Cell shape changes during gastrulation in Drosophila
M. Leptin, B. Grunewald
Development 1990 110: 73-84;
- First to describe ventral furrow formation?
> We divide the formation of the mesodermal germ layer into two phases. During the first phase, the ventral epithelium folds into a tube by a series of concerted cell shape changes (ventral furrow formation). Based on the behaviour of cells in this phase, we conclude that the prospective mesoderm is not a homogeneous cell population, but consists of two subpopulations. Each subpopulation goes through a distinctive sequence of specific cell shape changes which together mediate the invagination of the ventral furrow. In the second phase, the invaginated tube of mesoderm loses its epithelial character, the mesoderm cells disperse, divide and then spread out along the ectoderm to form a single cell layer.

twist and snail as positive and negative regulators during Drosophila mesoderm development.
M Leptin
Max Planck Institut für Entwicklungsbiologie, Tübingen, Germany.
1991
- continues work on drophila gastrulation
- describes two genes required for ventral furrow formation?

Control of Drosophila gastrulation by apical localization of adherens junctions and RhoGEF2
M Leptin
2007
- more recent work on drosophila gastrulation. uses fluorescence microscopy to carefully study the ventral furrow. signal is good enough to make out individual cells in 2D slice. even when ventral furrow is totally folded.
    - Is this live imaging?

Fully convolutional networks for semantic segmentation
CVPR 2015, Cited by 5318, 
J Long, E Shelhamer, T Darrell
- This model used skip connections but not a mirror-symmetric architecture like the U-net.

Mon Aug  6 13:29:08 2018

Detection of blob objects in microscopic zebrafish images based on gradient vector diffusion
2007
34 citations
G Li, T Liu, J Nie, L Guo, J Malicki… - Cytometry Part A …,
- sounds like they are doing cell counting and segmentation in this tissue!
- same technique as "A quantitative zebrafish phenotyping tool for developmental biology and disease modeling" ? 

An automated method for cell detection in zebrafish
Neuroinformatics 2008
35 citations
T Liu, G Li, J Nie, A Tarokh, X Zhou, L Guo, J Malicki…
- looks like the follow up to "Detection of blob objects in microscopic zebrafish images based on gradient vector diffusion"
 
A quantitative zebrafish phenotyping tool for developmental biology and disease modeling
IEEE Signal Processing Magazine, 2007
14 cites
T Liu
> This method is composed of three key steps. The first step is to produce a
diffused gradient vector field by a physical elastic deformable model. In the second step, the flux image is computed on the diffused gradient vector field. The third step per- forms thresholding and nonmaximum suppression based on the flux image. We report the validation and experimental results of this method using zebrafish image datasets from three independent research labs. Both sensitivity and specificity of this method are over 90%. This method is able to differentiate closely juxtaposed or connected blob objects, with high sensitivity and specificity in different situations. It is characterized by a good, consistent performance in blob object detection.
- Looks like very good, general blob detection! No learning required!

Segmentation of touching cell nuclei using gradient flow tracking
Li, Gang, Tianming Liu, J. Nie, L. Guo, J. Chen, J. Zhu, Weiming Xia, A. Mara, S. Holley, and S. T. C. Wong. "Segmentation of touching cell nuclei using gradient flow tracking." Journal of Microscopy 231, no. 1 (2008): 47-58.
62 cites
- related to "An automated method for cell detection in zebrafish"

A hybrid 3D watershed algorithm incorporating gradient cues and object models for automatic segmentation of nuclei in confocal image stacks
Lin, Gang, Umesh Adiga, Kathy Olson, John F. Guzowski, Carol A. Barnes, and Badrinath Roysam. "A hybrid 3D watershed algorithm incorporating gradient cues and object models for automatic segmentation of nuclei in confocal image stacks." Cytometry Part A: the journal of the International Society for Analytical Cytology 56, no. 1 (2003): 23-36.
cited 339

@article{lin2007multi,
  title={A multi-model approach to simultaneous segmentation and classification of heterogeneous populations of cell nuclei in 3D confocal microscope images},
  author={Lin, Gang and Chawla, Monica K and Olson, Kathy and Barnes, Carol A and Guzowski, John F and Bjornsson, Christopher and Shain, William and Roysam, Badrinath},
  journal={Cytometry Part A: The Journal of the International Society for Analytical Cytology},
  volume={71},
  number={9},
  pages={724--736},
  year={2007},
  publisher={Wiley Online Library}
}
cited 115

@article{lin2005hierarchical,
  title={Hierarchical, model-based merging of multiple fragments for improved three-dimensional segmentation of nuclei},
  author={Lin, Gang and Chawla, Monica K and Olson, Kathy and Guzowski, John F and Barnes, Carol A and Roysam, Badrinath},
  journal={Cytometry Part A: The Journal of the International Society for Analytical Cytology},
  volume={63},
  number={1},
  pages={20--33},
  year={2005},
  publisher={Wiley Online Library}
}
cited 131

@article{malpica1997applying,
  title={Applying watershed algorithms to the segmentation of clustered nuclei},
  author={Malpica, Norberto and de Solorzano, Carlos Ortiz and Vaquero, Juan Jos{\'e} and Santos, Andr{\'e}s and Vallcorba, Isabel and Garc{\'\i}a-Sagredo, Jos{\'e} Miguel and Del Pozo, Francisco},
  journal={Cytometry},
  volume={28},
  number={4},
  pages={289--297},
  year={1997},
  publisher={Wiley Online Library}
}
cited 466

@article{jesper1999artificial,
  title={Artificial neural network-aided image analysis system for cell counting},
  author={Jesper Sj{\"o}str{\"o}m, Per and Frydel, Beata Ras and Wahlberg, Lars Ulrik},
  journal={Cytometry: The Journal of the International Society for Analytical Cytology},
  volume={36},
  number={1},
  pages={18--26},
  year={1999},
  publisher={Wiley Online Library}
}
cited 77
- amazing that people were using neural nets 20 years ago!
> A  three-layer  feed-forward  network with extensive weight sharing in the first hidden layer was employed and trained on 1,830 examples using the error back-propagation algorithm on a Power Macintosh 7300/ 180  desktop  computer.  The  optimal  number  of  hidden neurons  was  determined  and  the  trained  system  was validated  by  comparison  with  blinded  human  counts.
> The  correlation  index  at  100x  magnification neared person-to-person variability, while 50x magnifica- tion  was  not  useful.  The  system  was  approximately  six times faster than an experienced human.

All-optical machine learning using diffractive deep neural networks
Xing Lin1,2,3,*, Yair Rivenson1,2,3,*, Nezih T. Yardimci1,3, Muhammed Veli1,2,3, Yi Luo1,2,3, Mona Jarrahi1,3, Aydogan Ozcan1,2,3,4,†

Wed Aug 15 14:17:00 2018

@article{olivier2010cell,
  title={Cell lineage reconstruction of early zebrafish embryos using label-free nonlinear microscopy},
  author={Olivier, Nicolas and Luengo-Oroz, Miguel A and Duloquin, Louise and Faure, Emmanuel and Savy, Thierry and Veilleux, Isra{\"e}l and Solinas, Xavier and D{\'e}barre, Delphine and Bourgine, Paul and Santos, Andr{\'e}s and others},
  journal={Science},
  volume={329},
  number={5994},
  pages={967--971},
  year={2010},
  publisher={American Association for the Advancement of Science}}
cite 282
spoke at lightsheet conf
> Blastomeres continuously drift out of synchrony. After the 32-cell stage, the cell cycle lengthens according to cell radial position, leading to apparent division waves. Progressive amplification of this process is the rule, contrasting with classical descriptions of abrupt changes in the system dynamics.
- For segmentation technique see below

@article{zanella2010cells,
  title={Cells segmentation from 3-D confocal images of early zebrafish embryogenesis},
  author={Zanella, Cecilia and Campana, Matteo and Rizzi, Barbara and Melani, Camilo and Sanguinetti, Gonzalo and Bourgine, Paul and Mikula, Karol and Peyri{\'e}ras, Nadine and Sarti, Alessandro},
  journal={IEEE transactions on Image Processing},
  volume={19},
  number={3},
  pages={770--781},
  year={2010},
  publisher={IEEE}}
cite 100
> Our strategy in- cludes the following steps: the signal-to-noise ratio is first improved by an edge-preserving filtering, then the cell shape is reconstructed applying a fully automated algorithm based on a generalized ver- sion of the Subjective Surfaces technique.

@article{sarti2000subjective,
  title={Subjective surfaces: A method for completing missing boundaries},
  author={Sarti, Alessandro and Malladi, Ravi and Sethian, James A},
  journal={Proceedings of the National Academy of Sciences},
  volume={97},
  number={12},
  pages={6258--6263},
  year={2000},
  publisher={National Acad Sciences}}
cite 124

@article{chen2017voxresnet,
  title={VoxResNet: Deep voxelwise residual networks for brain segmentation from 3D MR images},
  author={Chen, Hao and Dou, Qi and Yu, Lequan and Qin, Jing and Heng, Pheng-Ann},
  journal={NeuroImage},
  year={2017},
  publisher={Elsevier}}
cite 48
Resnet. semantic segmentation. not instance seg.


@inproceedings{cirecsan2013mitosis,
  title={Mitosis detection in breast cancer histology images with deep neural networks},
  author={Cire{\c{s}}an, Dan C and Giusti, Alessandro and Gambardella, Luca M and Schmidhuber, J{\"u}rgen},
  booktitle={International Conference on Medical Image Computing and Computer-assisted Intervention},
  pages={411--418},
  year={2013},
  organization={Springer}}
cited 637
miccai 2013
patch->pixel network
2-class pixelwise classification.
background and non-mitotic nuclei pixels are same class
requires centroid annotations of mitotic nuclei only
rotation + flipping aug
trained for 30 epochs = 1 day of training on GPU!
5x conv.maxpool + 2x fully-conn
> the mitosis class is assigned to all windows whose center pixel is closer than d = 10 pixels to the centroid of a ground-truth mitosis; all remaining windows are given the non-mitosis class. This results in a total of roughly 66000 mitosis pixels and 151 million non-mitosis pixels.

@article{li2018deepmitosis,
  title={DeepMitosis: Mitosis detection via deep detection, verification and segmentation networks},
  author={Li, Chao and Wang, Xinggang and Liu, Wenyu and Latecki, Longin Jan},
  journal={Medical image analysis},
  volume={45},
  pages={121--133},
  year={2018},
  publisher={Elsevier}}
2 cites
3 nets
> It consists of three components: a deep segmentation model based on FCN for producing estimated bounding box labels, a deep detection model based on Faster R-CNN for localizing mitosis, and a deep verification model based on ResNet (He et al., 2016 ) for classifying the detection patches to further improve the accuracy.
- 2012 MITOSIS challenge has pixelwise class labels
- 2014 MITOSIS challenge has centroid labels
train FCN on 2012 data
segment 2014 data w this FCN.
get bboxes for 2014 by combining segmentation w centroid annotations
train detector w these bboxes

@article{malpica1997applying,
  title={Applying watershed algorithms to the segmentation of clustered nuclei},
  author={Malpica, Norberto and de Solorzano, Carlos Ortiz and Vaquero, Juan Jos{\'e} and Santos, Andr{\'e}s and Vallcorba, Isabel and Garc{\'\i}a-Sagredo, Jos{\'e} Miguel and Del Pozo, Francisco},
  journal={Cytometry},
  volume={28},
  number={4},
  pages={289--297},
  year={1997},
  publisher={Wiley Online Library}}
cited 467

@article{santella2010hybrid,
  title={A hybrid blob-slice model for accurate and efficient detection of fluorescence labeled nuclei in 3D},
  author={Santella, Anthony and Du, Zhuo and Nowotschin, Sonja and Hadjantonakis, Anna-Katerina and Bao, Zhirong},
  journal={BMC bioinformatics},
  volume={11},
  number={1},
  pages={580},
  year={2010},
  publisher={BioMed Central}}
cited 75

@article{lin2003hybrid,
  title={A hybrid 3D watershed algorithm incorporating gradient cues and object models for automatic segmentation of nuclei in confocal image stacks},
  author={Lin, Gang and Adiga, Umesh and Olson, Kathy and Guzowski, John F and Barnes, Carol A and Roysam, Badrinath},
  journal={Cytometry Part A: the journal of the International Society for Analytical Cytology},
  volume={56},
  number={1},
  pages={23--36},
  year={2003},
  publisher={Wiley Online Library}}
cited 339

@article{thierbach2018combining,
  title={Combining Deep Learning and Active Contours Opens The Way to Robust, Automated Analysis of 3D Brain Cytoarchitectonics},
  author={Thierbach, Konstantin and Bazin, Pierre-Louis and de Back, Walter and Gavriilidis, Filippos and Kirilina, Evgeniya and J{\"a}ger, Carsten and Morawski, Markus and Geyer, Stefan and Weiskopf, Nikolaus and Scherf, Nico},
  year={2018}}
0 cites
Nico Sherf and Walter de Back!
Knows about and Cites "Fully Convolutional Regression Networks"
bioarxiv posted Apr. 9, 2018
> The  current  state  of  the  art  for  density  estima- tion in 2-D is achieved through using Fully Convolutional Regression Networks (FCRNs)  which  out-perform  regression  decision  trees  with  sufficient  training [19]. In this study we decided to use regression random decision trees however, due  to  there  high  speed  and  their  top  performance,  especially  with  relatively small  amounts  of  training.  Processing  time  when  analysing  3-D  data  is  a  key consideration  and  also,  in  biomedical  applications,  dataset  sizes  can  be  small and so optimum performance with a small amount of training is key advantage.
- Rejected from MIDL2018 conf.
- Use something called Mixed-scale Dense Network (MS-D)
    - Say that it improves on the FCRN density kernel estimation approach but i don't see why it should... just trying to classify a small region of pixels...
> In contrast to Thierbach et al. (2018) we use the Mixed-scale Dense Network (MS-D) architecture by Pelt and Sethian (2018) to directly predict masks of cell centroid regions in 3D. This step turned out to be more robust in 3D compared to regressing the Gaussian-smoothed centroid positions as proposed in Xie et al. (2016).  An additional advantage of the MS-D architecture is the smaller number of parameters to reduce overfitting and the intrinsic parallel, multi-scale processing without resolution bottlenecks and upsampling steps.

@article{thierbach2018deep,
  title={Deep Learning meets Topology-preserving Active Contours: towards scalable quantitative histology of cortical cytoarchitecture.},
  author={Thierbach, Konstantin and Bazin, Pierre-Louis and Gavriilidis, Filippos and Kirilina, Evgeniya and Jaeger, Carsten and Morawski, Markus and Geyer, Stefan and Weiskopf, Nikolaus and Scherf, Nico},
  journal={bioRxiv},
  pages={297689},
  year={2018},
  publisher={Cold Spring Harbor Laboratory}}
1 cite
Nico Sherf
Uses FCRNs for centerpoint prediction
Uses predicted centerpoints as seeds for classical active contour model
2d only!!! But is easy to extend to 3D!

@inproceedings{waithe20163,
  title={3-D density kernel estimation for counting in microscopy image volumes using 3-D image filters and random decision trees},
  author={Waithe, Dominic and Hailstone, Martin and Lalwani, Mukesh Kumar and Parton, Richard and Yang, Lu and Patient, Roger and Eggeling, Christian and Davis, Ilan},
  booktitle={European Conference on Computer Vision},
  pages={244--255},
  year={2016},
  organization={Springer}}
First paper to do density kernel estimation in 3D microscopy imgs (2016)
uses regression trees on density kernels
0 cites
- why is it not referenced by any papers yet?
- They cite: Lempitsky, V., and Zisserman, A. Learning to count objects in images. In Advances
in Neural Information Processing Systems (2010), pp. 1324-1332.
- 14.  Fiaschi,  L.,  Nair,  R.,  Koethe,  U.,  Hamprecht,  F.,  et  al.  Learning  to  count  with
regression forest and structured labels. In Pattern Recognition (ICPR), 2012 21st
- International Conference on (2012), IEEE, pp. 2685-2688.
15.  Arteta, C., Lempitsky, V., Noble, J. A., and Zisserman, A. Interactive object count-
ing. In Computer VisionECCV 2014. Springer, 2014, pp. 504-518.
16.  Waithe, D., Rennert, P., Brostow, G., and Piper, M. D. Quantifly: Robust trainable
software for automated drosophila egg counting. PloS one 10.5 (2015): e0127659
The



@article{pelt2017mixed,
  title={A mixed-scale dense convolutional neural network for image analysis},
  author={Pelt, Dani{\"e}l M and Sethian, James A},
  journal={Proceedings of the National Academy of Sciences},
  pages={201715832},
  year={2017},
  publisher={National Acad Sciences}}
6 cites
mixed-scale dense network cited by @thierbach2018combining
published in PNAS???
> Here, we introduce a network architecture based on using dilated convolutions to capture features at different image scales and densely connecting all feature maps with each other...
We compare results of the proposed network architecture with popular existing architectures for several segmentation problems, showing that the proposed architecture is able to achieve accurate results with fewer parameters, with a reduced risk of overfitting the training data.
- Uses a really cool toy simulated dataset!
- Compares extensively against U-net and beats it every time on every task.
- Biological segmentation task is 3D tomography data

@article{bogovic2013multiple,
  title={A multiple object geometric deformable model for image segmentation},
  author={Bogovic, John A and Prince, Jerry L and Bazin, Pierre-Louis},
  journal={Computer Vision and Image Understanding},
  volume={117},
  number={2},
  pages={145--157},
  year={2013},
  publisher={Elsevier}}
- active contour model used in thierbach2018deep
- member of Stephan Saalfeld's lab!

@inproceedings{bai2017deep,
  title={Deep watershed transform for instance segmentation},
  author={Bai, Min and Urtasun, Raquel},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={2858--2866},
  year={2017},
  organization={IEEE}}
cited 50

@inproceedings{bearman2016s,
  title={What’s the point: Semantic segmentation with point supervision},
  author={Bearman, Amy and Russakovsky, Olga and Ferrari, Vittorio and Fei-Fei, Li},
  booktitle={European Conference on Computer Vision},
  pages={549--565},
  year={2016},
  organization={Springer}}
cited 120
annotators point to an object if one exists
they compare to other types of annotations

@article{lehtinen2018noise2noise,
  title={Noise2Noise: Learning Image Restoration without Clean Data},
  author={Lehtinen, Jaakko and Munkberg, Jacob and Hasselgren, Jon and Laine, Samuli and Karras, Tero and Aittala, Miika and Aila, Timo},
  journal={arXiv preprint arXiv:1803.04189},
  year={2018}}
arxiv version. no citations yet?
How is this related to learning from semi-automated GT ?
same: If the net can't learn any consistent pattern to the noise/artifacts
diff: Noisy image pairs... we have two different kinds of images and two different kinds of "noise".

@article{lu2017learning,
  title={Learning from weak and noisy labels for semantic segmentation},
  author={Lu, Zhiwu and Fu, Zhenyong and Xiang, Tao and Han, Peng and Wang, Liwei and Gao, Xin},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={39},
  number={3},
  pages={486--500},
  year={2017},
  publisher={IEEE}}
cite 18
doesn't solve our problem. they assume a good segmentation algorithm, then worry about
the problem of assigning labels...


@article{reed2014training,
  title={Training deep neural networks on noisy labels with bootstrapping},
  author={Reed, Scott and Lee, Honglak and Anguelov, Dragomir and Szegedy, Christian and Erhan, Dumitru and Rabinovich, Andrew},
  journal={arXiv preprint arXiv:1412.6596},
  year={2014}}
cite 118


@article{sukhbaatar2014training,
  title={Training convolutional networks with noisy labels},
  author={Sukhbaatar, Sainbayar and Bruna, Joan and Paluri, Manohar and Bourdev, Lubomir and Fergus, Rob},
  journal={arXiv preprint arXiv:1406.2080},
  year={2014}}
cite 72

@inproceedings{chen2015webly,
  title={Webly supervised learning of convolutional networks},
  author={Chen, Xinlei and Gupta, Abhinav},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1431--1439},
  year={2015}}
cite 125

@article{kraus2016classifying,
  title={Classifying and segmenting microscopy images with deep multiple instance learning},
  author={Kraus, Oren Z and Ba, Jimmy Lei and Frey, Brendan J},
  journal={Bioinformatics},
  volume={32},
  number={12},
  pages={i52--i59},
  year={2016},
  publisher={Oxford University Press}}
cite 73
They use image-level labels to classify and segment cells!
They also talk about robustness in the face of label noise.
- Is this the paper Laurent saw at last year's MICCAI? No it's a bioinformatics paper.
So the technique of using pooling to do instance-level labeling from image-level annotations 
must be well known...

@article{zhao2018automatic,
  title={Automatic recognition of holistic functional brain networks using iteratively optimized convolutional neural networks (IO-CNN) with weak label initialization},
  author={Zhao, Yu and Ge, Fangfei and Liu, Tianming},
  journal={Medical image analysis},
  volume={47},
  pages={111--126},
  year={2018},
  publisher={Elsevier}}
new
use iterative optimization with weak initial labeling
brain f-MRI data

@inproceedings{pachitariu2013extracting,
  title={Extracting regions of interest from biological images with convolutional sparse block coding},
  author={Pachitariu, Marius and Packer, Adam M and Pettit, Noah and Dalgleish, Henry and Hausser, Michael and Sahani, Maneesh},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1745--1753},
  year={2013}}
cite 48
ref'd by [@kraus2016classifying] as work that doesn't require pixel-level labeling

[1] K. E. G Magnusson, J. Jaldén, P. M. Gilbert, A. L. Chan, B. D. Cosgrove, and H. M. Blau, "The Baxter Algorithms, a software package for tracking and analysis of cells," In preparation

@phdthesis{magnusson2016segmentation,
  title={Segmentation and tracking of cells and particles in time-lapse microscopy},
  author={Magnusson, Klas EG},
  year={2016},
  school={KTH Royal Institute of Technology}}
- cited 3!!!
- Doctoral Thesis!
- Current leader across many datasets
- custum, rule-based, many parameter model. no automated learning. all hand-optimized.
- gets 0.898 TRA score on celegans data! but only 0.479 on SEG. (still leader).
- also leads on DROSOPHILA. 0.657 TRA score and 0.561 SEG.

@article{magnusson2015global,
  title={Global linking of cell tracks using the Viterbi algorithm},
  author={Magnusson, Klas EG and Jald{\'e}n, Joakim and Gilbert, Penney M and Blau, Helen M},
  journal={IEEE transactions on medical imaging},
  volume={34},
  number={4},
  pages={911--929},
  year={2015},
  publisher={IEEE}}
cite 72
- KEG Magnussen's most cited work. The basis for tracking in [@magnusson2016segmentation]
- 

@article{mace2013high,
  title={A high fidelity cell lineage tracing method for obtaining systematic spatiotemporal gene expression patterns in Caenorhabditis elegans},
  author={Mace, Daniel L and Weisdepp, Peter and Gevirtzman, Louis and Boyle, Thomas and Waterston, Robert H},
  journal={G3: Genes, Genomes, Genetics},
  pages={g3--113},
  year={2013},
  publisher={G3: Genes, Genomes, Genetics}}
cited 10
RH Waterston lab. provided the c. elegans images for ISBI challenge
- This is the super complicated model for tracking that allows them to track accurately until neuronal sub-specification
- No idea if it actually does *segmentation* or just fits rough shapes. It doesn't mention seg in the abstract... I think it fits shapes and mostly does lineage tracing.

@inproceedings{meijering2009tracking,
  title={Tracking in cell and developmental biology},
  author={Meijering, Erik and Dzyubachyk, Oleh and Smal, Ihor and van Cappellen, Wiggert A},
  booktitle={Seminars in cell \& developmental biology},
  volume={20},
  number={8},
  pages={894--902},
  year={2009},
  organization={Elsevier}}
cite 215
Remember to check out this review of tracking (in dev bio!) by Erik Meijering, et al.
But it's OLD.


@inproceedings{cook2011cuda,
  title={CUDA-level Performance with Python-level Productivity for Gaussian Mixture Model Applications.},
  author={Cook, Henry and Gonina, Ekaterina and Kamil, Shoaib and Friedland, Gerald and Patterson, David A and Fox, Armando},
  booktitle={HotPar},
  year={2011}}
Awesome! Let's track this down. If we can use python to run super fast parallel GMM fitting then
we can recreate Amat's algorithm within our framework...
was fitting 100 components w full covariance to 90k datapoints in 3 or more dimensions in < 1sec in 2011! on GPU.


@inproceedings{sokooti2017nonrigid,
  title={Nonrigid image registration using multi-scale 3D convolutional neural networks},
  author={Sokooti, Hessam and de Vos, Bob and Berendsen, Floris and Lelieveldt, Boudewijn PF and I{\v{s}}gum, Ivana and Staring, Marius},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={232--239},
  year={2017},
  organization={Springer}}
cited 20
These guys took our idea!
Artificially make warp fields to warp images and train a net to predict warp fields from image pairs...
- We should try using this for tracking!

@inproceedings{balakrishnan2018unsupervised,
  title={An Unsupervised Learning Model for Deformable Medical Image Registration},
  author={Balakrishnan, Guha and Zhao, Amy and Sabuncu, Mert R and Guttag, John and Dalca, Adrian V},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={9252--9260},
  year={2018}}
cite 7
related to [@sokooti2017nonrigid] above

@article{li2017non,
  title={Non-rigid image registration using fully convolutional networks with deep self-supervision},
  author={Li, Hongming and Fan, Yong},
  journal={arXiv preprint arXiv:1709.00799},
  year={2017}}
cite 5
also related to above

@article{mahapatra2018elastic,
  title={Elastic Registration of Medical Images With GANs},
  author={Mahapatra, Dwarikanath},
  journal={arXiv preprint arXiv:1805.02369},
  year={2018}}
none
everyone is doing the unsupervised medical image registration thing! wow

@inproceedings{bohm2018isoo,
  title={ISOO DL: Instance segmentation of overlapping biological objects using deep learning},
  author={B{\"o}hm, Anton and {\"U}cker, Annekathrin and J{\"a}ger, Tim and Ronneberger, Olaf and Falk, Thorsten},
  booktitle={Biomedical Imaging (ISBI 2018), 2018 IEEE 15th International Symposium on},
  pages={1225--1229},
  year={2018},
  organization={IEEE}}
cite 0
Ronneberger's paper from last year on 2D segmenting overlapping objects in brightfield microscopy.

@inproceedings{funke2018candidate,
  title={The candidate multi-cut for cell segmentation},
  author={Funke, Jan and Zhang, Chong and Pietzsch, Tobias and Ballester, Miguel A Gonzalez and Saalfeld, Stephan},
  booktitle={Biomedical Imaging (ISBI 2018), 2018 IEEE 15th International Symposium on},
  pages={649--653},
  year={2018},
  organization={IEEE}}
Funke's 2018 ISBI paper w Tobi and Saalfeld!


@article{hilsenbeck2017faster,
  title={fastER: a user-friendly tool for ultrafast and robust cell segmentation in large-scale microscopy},
  author={Hilsenbeck, Oliver and Schwarzfischer, Michael and Loeffler, Dirk and Dimopoulos, Sotiris and Hastreiter, Simon and Marr, Carsten and Theis, Fabian J and Schroeder, Timm},
  journal={Bioinformatics},
  volume={33},
  number={13},
  pages={2020--2028},
  year={2017},
  publisher={Oxford University Press}}
cite 7
Referenced by [@thierbach2018combining] and compared against as the only other benchmark segmentation. Strange because it also requires annotation?
- https://www.bsse.ethz.ch/csd/software/faster.html

@inproceedings{arteta2012learning,
  title={Learning to detect cells using non-overlapping extremal regions},
  author={Arteta, Carlos and Lempitsky, Victor and Noble, J Alison and Zisserman, Andrew},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={348--356},
  year={2012},
  organization={Springer}}
cite 133
- Referenced by [@hilsenbeck2017faster].

@article{xing2016robust,
  title={Robust nucleus/cell detection and segmentation in digital pathology and microscopy images: a comprehensive review},
  author={Xing, Fuyong and Yang, Lin},
  journal={IEEE reviews in biomedical engineering},
  volume={9},
  pages={234--263},
  year={2016},
  publisher={IEEE}}
cite 86
- cites detection from maximally stable extremal regions

@article{matas2004robust,
  title={Robust wide-baseline stereo from maximally stable extremal regions},
  author={Matas, Jiri and Chum, Ondrej and Urban, Martin and Pajdla, Tom{\'a}s},
  journal={Image and vision computing},
  volume={22},
  number={10},
  pages={761--767},
  year={2004},
  publisher={Elsevier}}
cite 4713
- classic paper on scene registration. MSER is now used for all kinds of detection problems.


@article{murray2006lineaging,
  title={The lineaging of fluorescently-labeled Caenorhabditis elegans embryos with StarryNite and AceTree},
  author={Murray, John Isaac and Bao, Zhirong and Boyle, Thomas J and Waterston, Robert H},
  journal={Nature protocols},
  volume={1},
  number={3},
  pages={1468},
  year={2006},
  publisher={Nature Publishing Group}
}
- cite 84
- software like Trackmate / Mamut for doing cell lineage analysis & curation
- 

@article{bao2006automated,
  title={Automated cell lineage tracing in Caenorhabditis elegans},
  author={Bao, Zhirong and Murray, John I and Boyle, Thomas and Ooi, Siew Loon and Sandel, Matthew J and Waterston, Robert H},
  journal={Proceedings of the National Academy of Sciences},
  volume={103},
  number={8},
  pages={2707--2712},
  year={2006},
  publisher={National Acad Sciences}
}
- cited 289
- StarryNite: original waterston paper for c. elegans tracking. 
- fits circles for cell detection. also does initial mitosis detection to identify dividing cells
- nearest-neighbor tracking is sufficient everywhere except for divisions!
- They have heuristic rules and costs that are functions of multiple timepoints for disambiguating divions.
- 

@article{li2008cell,
  title={Cell population tracking and lineage construction with spatiotemporal context},
  author={Li, Kang and Miller, Eric D and Chen, Mei and Kanade, Takeo and Weiss, Lee E and Campbell, Phil G},
  journal={Medical image analysis},
  volume={12},
  number={5},
  pages={546--566},
  year={2008},
  publisher={Elsevier}
}
- cited 329
- one of the first lineaging software pieces. along with StarryNite.

@inproceedings{kainmueller2014active,
  title={Active graph matching for automatic joint segmentation and annotation of C. elegans},
  author={Kainmueller, Dagmar and Jug, Florian and Rother, Carsten and Myers, Gene},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={81--88},
  year={2014},
  organization={Springer}
}
- cited 7
- actually does something very similar to our tracking approach!! they have 2nd order costs which are functions of two matching edges! And what's really cool... they optimize in a two-step way:
 1. first a fast optimization w gradient info in smooth space for rigid registration\
 2. a local (ILP-solving?) matching step which evaluates how well proposal matches to atlas.


@article{qu2011simultaneous,
  title={Simultaneous recognition and segmentation of cells: application in C. elegans},
  author={Qu, Lei and Long, Fuhui and Liu, Xiao and Kim, Stuart and Myers, Eugene and Peng, Hanchuan},
  journal={Bioinformatics},
  volume={27},
  number={20},
  pages={2895--2902},
  year={2011},
  publisher={Oxford University Press}
}
- cited 24
Simultaneous Recognition and Segmentation of Cells

@article{long20093d,
  title={A 3D digital atlas of C. elegans and its application to single-cell analyses},
  author={Long, Fuhui and Peng, Hanchuan and Liu, Xiao and Kim, Stuart K and Myers, Eugene},
  journal={Nature methods},
  volume={6},
  number={9},
  pages={667},
  year={2009},
  publisher={Nature Publishing Group}
}
- cited 148
A 3D Digital Atlas of C. Elegans and its Application to Single-Cell Analyses





